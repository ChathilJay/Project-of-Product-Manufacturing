{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a775be81",
   "metadata": {},
   "source": [
    "# Data Cleaning and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbeb1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06919380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        VYP batch         Part        Set Time  FFTE Feed solids SP  \\\n",
      "0  102_2019_07_02  Yeast - BRN  2/07/2019 0:10                 50.0   \n",
      "1  102_2019_07_02  Yeast - BRN  2/07/2019 0:10                 50.0   \n",
      "2  102_2019_07_02  Yeast - BRN  2/07/2019 0:10                 50.0   \n",
      "3  102_2019_07_02  Yeast - BRN  2/07/2019 0:10                 50.0   \n",
      "4  102_2019_07_02  Yeast - BRN  2/07/2019 0:10                 50.0   \n",
      "\n",
      "   FFTE Production solids SP  FFTE Steam pressure SP  TFE Out flow SP  \\\n",
      "0                      41.09                  118.44          2186.05   \n",
      "1                      41.09                  118.44          2186.05   \n",
      "2                      41.09                  118.44          2186.05   \n",
      "3                      41.09                  118.44          2186.05   \n",
      "4                      41.09                  118.44          2186.05   \n",
      "\n",
      "   TFE Production solids SP  TFE Vacuum pressure SP  TFE Steam pressure SP  \\\n",
      "0                      67.0                  -79.82                  125.0   \n",
      "1                      67.0                  -79.82                  125.0   \n",
      "2                      67.0                  -79.82                  125.0   \n",
      "3                      67.0                  -79.82                  125.0   \n",
      "4                      67.0                  -79.82                  125.0   \n",
      "\n",
      "   ...  TFE Out flow PV  TFE Product out temperature  \\\n",
      "0  ...          1942.93                            0   \n",
      "1  ...          1942.93                            0   \n",
      "2  ...          1942.93                            0   \n",
      "3  ...          1942.93                            0   \n",
      "4  ...          1942.93                            0   \n",
      "\n",
      "   TFE Production solids PV  TFE Production solids density  \\\n",
      "0                     64.92                           1.13   \n",
      "1                     64.92                           1.13   \n",
      "2                     64.92                           1.13   \n",
      "3                     64.92                           1.13   \n",
      "4                     64.92                           1.13   \n",
      "\n",
      "   TFE Steam pressure PV  TFE Steam temperature  TFE Tank level  \\\n",
      "0                 125.03                  64.79           44.61   \n",
      "1                 125.03                  64.79           44.61   \n",
      "2                 125.03                  64.79           44.61   \n",
      "3                 125.03                  64.79           44.61   \n",
      "4                 125.03                  64.79           44.61   \n",
      "\n",
      "   TFE Temperature  TFE Vacuum pressure PV  Quality  \n",
      "0               70                   -80.2     good  \n",
      "1               70                   -80.2     good  \n",
      "2               70                   -80.2     good  \n",
      "3               70                   -80.2     good  \n",
      "4               70                   -80.2     good  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the three datasets\n",
    "good_df = pd.read_csv(\"good.csv\")\n",
    "low_bad_df = pd.read_csv(\"low bad.csv\")\n",
    "high_bad_df = pd.read_csv(\"high bad.csv\")\n",
    "\n",
    "# Add a new column to identify the quality class\n",
    "good_df['Quality'] = 'good'\n",
    "low_bad_df['Quality'] = 'low_bad'\n",
    "high_bad_df['Quality'] = 'high_bad'\n",
    "\n",
    "# Combine all three into a single dataset\n",
    "combined_df = pd.concat([good_df, low_bad_df, high_bad_df], ignore_index=True)\n",
    "\n",
    "# Preview the combined dataset\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a87118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "combined_df.columns = (\n",
    "    combined_df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# Convert Set Time to datetime\n",
    "combined_df['set_time'] = pd.to_datetime(combined_df['set_time'], dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b814cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns:\n",
      " ['vyp_batch', 'part', 'set_time', 'ffte_feed_solids_sp', 'ffte_production_solids_sp', 'ffte_steam_pressure_sp', 'tfe_out_flow_sp', 'tfe_production_solids_sp', 'tfe_vacuum_pressure_sp', 'tfe_steam_pressure_sp', 'extract_tank_level', 'ffte_discharge_density', 'ffte_discharge_solids', 'ffte_feed_flow_rate_pv', 'ffte_feed_solids_pv', 'ffte_heat_temperature_1', 'ffte_heat_temperature_2', 'ffte_heat_temperature_3', 'ffte_production_solids_pv', 'ffte_steam_pressure_pv', 'tfe_input_flow_pv', 'tfe_level', 'tfe_motor_current', 'tfe_motor_speed', 'tfe_out_flow_pv', 'tfe_product_out_temperature', 'tfe_production_solids_pv', 'tfe_production_solids_density', 'tfe_steam_pressure_pv', 'tfe_steam_temperature', 'tfe_tank_level', 'tfe_temperature', 'tfe_vacuum_pressure_pv', 'quality']\n",
      "\n",
      "Set Point (SP) columns: 8 → ['ffte_feed_solids_sp', 'ffte_production_solids_sp', 'ffte_steam_pressure_sp', 'tfe_out_flow_sp', 'tfe_production_solids_sp', 'tfe_vacuum_pressure_sp', 'tfe_steam_pressure_sp', 'tfe_motor_speed']\n",
      "\n",
      "Process Variable (PV) columns: 9 → ['ffte_feed_flow_rate_pv', 'ffte_feed_solids_pv', 'ffte_production_solids_pv', 'ffte_steam_pressure_pv', 'tfe_input_flow_pv', 'tfe_out_flow_pv', 'tfe_production_solids_pv', 'tfe_steam_pressure_pv', 'tfe_vacuum_pressure_pv']\n",
      "\n",
      "Other columns: 13 → ['tfe_motor_current', 'ffte_discharge_solids', 'ffte_heat_temperature_2', 'tfe_product_out_temperature', 'tfe_tank_level', 'extract_tank_level', 'ffte_discharge_density', 'tfe_level', 'tfe_production_solids_density', 'tfe_temperature', 'ffte_heat_temperature_1', 'ffte_heat_temperature_3', 'tfe_steam_temperature']\n"
     ]
    }
   ],
   "source": [
    "# Preview all columns\n",
    "print(\"All columns:\\n\", combined_df.columns.tolist())\n",
    "\n",
    "# Create lists based on column naming patterns\n",
    "sp_columns = [col for col in combined_df.columns if \"_sp\" in col]\n",
    "pv_columns = [col for col in combined_df.columns if \"_pv\" in col]\n",
    "\n",
    "# Metadata columns (manually listed)\n",
    "meta_columns = ['vyp_batch', 'part', 'set_time', 'quality']\n",
    "\n",
    "# Optional: Remaining system-specific or ungrouped columns\n",
    "other_columns = list(set(combined_df.columns) - set(sp_columns) - set(pv_columns) - set(meta_columns))\n",
    "\n",
    "# Print summaries\n",
    "print(f\"\\nSet Point (SP) columns: {len(sp_columns)} →\", sp_columns)\n",
    "print(f\"\\nProcess Variable (PV) columns: {len(pv_columns)} →\", pv_columns)\n",
    "print(f\"\\nOther columns: {len(other_columns)} →\", other_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc16d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sp_columns + pv_columns:\n",
    "    combined_df[f\"{col}_lag1\"] = combined_df[col].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf46fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sp_columns + pv_columns:\n",
    "    combined_df[f\"{col}_roll3\"] = combined_df[col].rolling(window=3).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dcf92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sp_columns + pv_columns:\n",
    "    combined_df[f\"{col}_delta\"] = combined_df[col].diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f322932",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.get_dummies(combined_df, columns=['part'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "490d92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b07266",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"combined_cleaned_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling mean over 3 steps\n",
    "for col in sp_columns + pv_columns:\n",
    "    combined_df[f\"{col}_roll3\"] = combined_df[col].rolling(window=3).mean()\n",
    "\n",
    "# Rate of change (delta)\n",
    "for col in sp_columns + pv_columns:\n",
    "    combined_df[f\"{col}_delta\"] = combined_df[col].diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d791bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode yeast type\n",
    "#combined_df = pd.get_dummies(combined_df, columns=['part'])\n",
    "\n",
    "# Drop nulls from lag/rolling/diff\n",
    "combined_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d9215ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define features and labels\n",
    "exclude = ['vyp_batch', 'set_time', 'quality']\n",
    "X = combined_df.drop(columns=exclude)\n",
    "y = combined_df['quality']\n",
    "\n",
    "# 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cde3d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.97      0.98      0.97      3990\n",
      "    high_bad       0.98      0.98      0.98      4349\n",
      "     low_bad       0.96      0.91      0.94       773\n",
      "\n",
      "    accuracy                           0.97      9112\n",
      "   macro avg       0.97      0.96      0.96      9112\n",
      "weighted avg       0.97      0.97      0.97      9112\n",
      "\n",
      "[[3901   64   25]\n",
      " [  77 4267    5]\n",
      " [  53   13  707]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa502d",
   "metadata": {},
   "source": [
    "# SP Recommendation via Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee3aeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only 'good' quality batches\n",
    "df_good = combined_df[combined_df['quality'] == 'good'].copy()\n",
    "\n",
    "# Select SP targets to predict\n",
    "sp_targets = [\n",
    "    'ffte_feed_solids_sp',\n",
    "    'ffte_production_solids_sp',\n",
    "    'tfe_production_solids_sp',\n",
    "    'tfe_steam_pressure_sp'\n",
    "]\n",
    "\n",
    "# Define input features (exclude meta and targets)\n",
    "exclude_cols = ['vyp_batch', 'set_time', 'quality'] + sp_targets\n",
    "X = df_good.drop(columns=exclude_cols)\n",
    "y = df_good[sp_targets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb12ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📍 ffte_feed_solids_sp\n",
      "MAE: 0.003064235223341878\n",
      "RMSE: 0.06770407091326419\n",
      "\n",
      "📍 ffte_production_solids_sp\n",
      "MAE: 0.00124665363212656\n",
      "RMSE: 0.017264871918907812\n",
      "\n",
      "📍 tfe_production_solids_sp\n",
      "MAE: 0.05355090239133742\n",
      "RMSE: 0.26167651005185627\n",
      "\n",
      "📍 tfe_steam_pressure_sp\n",
      "MAE: 0.03754699954880431\n",
      "RMSE: 0.6150874175332319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Wrap base regressor for multi-target prediction\n",
    "model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "model.fit(X, y) \n",
    "\n",
    "# Predict SPs\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate performance for each SP target\n",
    "for i, col in enumerate(y.columns):\n",
    "    print(f\"\\n📍 {col}\")\n",
    "    print(\"MAE:\", mean_absolute_error(y[col], y_pred[:, i]))\n",
    "    mse = mean_squared_error(y[col], y_pred[:, i])\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e0109",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "753f41f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>Cause Category</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Total Time Mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-04 13:30:00</td>\n",
       "      <td>TFE</td>\n",
       "      <td>Low Solids</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-04 15:25:00</td>\n",
       "      <td>TFE</td>\n",
       "      <td>Low Solids</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-04 15:45:00</td>\n",
       "      <td>TFE</td>\n",
       "      <td>Low Solids</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-04 18:00:00</td>\n",
       "      <td>TFE</td>\n",
       "      <td>Low Solids</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-04 20:10:00</td>\n",
       "      <td>TFE</td>\n",
       "      <td>Low Solids</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_time Cause Category       Cause  Total Time Mins\n",
       "0 2020-05-04 13:30:00            TFE  Low Solids               30\n",
       "1 2020-05-04 15:25:00            TFE  Low Solids               10\n",
       "2 2020-05-04 15:45:00            TFE  Low Solids               10\n",
       "3 2020-05-04 18:00:00            TFE  Low Solids               10\n",
       "4 2020-05-04 20:10:00            TFE  Low Solids               15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the downtime dataset\n",
    "downtime_df = pd.read_csv(\"downtime.csv\")\n",
    "\n",
    "# Create downtime timestamp\n",
    "downtime_df['event_time'] = pd.to_datetime(\n",
    "    downtime_df['Production Date'] + ' ' + downtime_df['Time'],\n",
    "    dayfirst=True,\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Keep only relevant columns for now\n",
    "downtime_df = downtime_df[['event_time', 'Cause Category', 'Cause', 'Total Time Mins']]\n",
    "downtime_df.dropna(subset=['event_time'], inplace=True)\n",
    "\n",
    "# Preview\n",
    "downtime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7ed5ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anomaly\n",
       "0    29947\n",
       "1      426\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load main cleaned dataset (if not already loaded)\n",
    "combined_df = pd.read_csv(\"combined_cleaned_features.csv\", parse_dates=['set_time'])\n",
    "\n",
    "# Add a new anomaly label column, default = 0 (normal)\n",
    "combined_df['anomaly'] = 0\n",
    "\n",
    "# Define how close to a downtime event counts as \"anomaly\" (in minutes)\n",
    "window_minutes = 15\n",
    "\n",
    "# Loop through downtime events and flag nearby rows\n",
    "for downtime_time in downtime_df['event_time']:\n",
    "    mask = (\n",
    "        (combined_df['set_time'] >= downtime_time - pd.Timedelta(minutes=window_minutes)) &\n",
    "        (combined_df['set_time'] <= downtime_time + pd.Timedelta(minutes=window_minutes))\n",
    "    )\n",
    "    combined_df.loc[mask, 'anomaly'] = 1\n",
    "\n",
    "# Preview result\n",
    "combined_df['anomaly'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d071a09",
   "metadata": {},
   "source": [
    "Train Anomaly Detection Model (Isolation Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c3e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-feature columns\n",
    "exclude_cols = ['vyp_batch', 'set_time', 'quality', 'anomaly']\n",
    "X_anomaly = combined_df.drop(columns=[col for col in exclude_cols if col in combined_df.columns])\n",
    "\n",
    "# Labels (for evaluation only — not used in training)\n",
    "y_anomaly = combined_df['anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d9ab8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     29947\n",
      "           1       0.05      0.18      0.07       426\n",
      "\n",
      "    accuracy                           0.94     30373\n",
      "   macro avg       0.52      0.57      0.52     30373\n",
      "weighted avg       0.97      0.94      0.95     30373\n",
      "\n",
      "[[28369  1578]\n",
      " [  348    78]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "iso_model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "iso_model.fit(X_anomaly)\n",
    "\n",
    "# Predict anomalies: -1 = anomaly, 1 = normal\n",
    "y_pred_iso = iso_model.predict(X_anomaly)\n",
    "y_pred_iso = [1 if val == -1 else 0 for val in y_pred_iso]  # convert to 1=anomaly, 0=normal\n",
    "\n",
    "print(classification_report(y_anomaly, y_pred_iso))\n",
    "print(confusion_matrix(y_anomaly, y_pred_iso))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
